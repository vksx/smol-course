# Parameter-Efficient Fine-Tuning (PEFT) (Ajuste Fino com Efici√™ncia de Par√¢metro)

√Ä medida que os modelos de linguagem aumentam, o ajuste fino tradicional torna-se cada vez mais desafiador. O ajuste fino completo de um modelo com 1,7 bilh√£o de par√¢metros requer uma quantidade consider√°vel de mem√≥ria da GPU, torna caro o armazenamento de c√≥pias separadas do modelo e apresenta o risco de um esquecimento catastr√≥fico das capacidades originais do modelo. Os m√©todos de ajuste fino com efici√™ncia de par√¢metros (PEFT) abordam esses desafios modificando apenas um pequeno subconjunto de par√¢metros do modelo e mantendo a maior parte do modelo congelada.

O ajuste fino tradicional atualiza todos os par√¢metros do modelo durante o treinamento, o que se torna impratic√°vel para modelos grandes. Os m√©todos PEFT introduzem abordagens para adaptar modelos usando menos par√¢metros trein√°veis, geralmente menos de 1% do tamanho do modelo original. Essa redu√ß√£o dr√°stica nos par√¢metros trein√°veis permite:

- Ajuste fino no hardware do consumidor com mem√≥ria de GPU limitada
- Armazenamento eficiente de v√°rias adapta√ß√µes de tarefas espec√≠ficas
- Melhor generaliza√ß√£o em cen√°rios com poucos dados
- Ciclos de treinamento e itera√ß√£o mais r√°pidos

## M√©todos Dispon√≠veis

Neste m√≥dulo, abordaremos dois m√©todos populares de PEFT:

### 1Ô∏è‚É£ LoRA (Low-Rank Adaptation - Adapta√ß√£o de Baixa Classifica√ß√£o)

O LoRA surgiu como o m√©todo PEFT mais amplamente adotado, oferecendo uma solu√ß√£o elegante para a adapta√ß√£o eficiente do modelo. Em vez de modificar o modelo inteiro, o **LoRA injeta matrizes trein√°veis nas camadas de aten√ß√£o do modelo.**  Essa abordagem normalmente reduz os par√¢metros trein√°veis em cerca de 90%, mantendo um desempenho compar√°vel ao ajuste fino completo. Exploraremos o LoRA na se√ß√£o [LoRA (Adapta√ß√£o de Baixa Classifica√ß√£o)](./lora_adapters.md).
 
### 2Ô∏è‚É£ Ajuste de Prompts

O ajuste de prompts oferece uma abordagem **ainda mais leve** ao **adicionar tokens trein√°veis √† entrada** em vez de modificar os pesos do modelo. O ajuste de prompt √© menos popular que o LoRA, mas pode ser uma t√©cnica √∫til para adaptar rapidamente um modelo a novas tarefas ou dom√≠nios. Exploraremos o ajuste de prompt na se√ß√£o [Ajuste de Prompt](./prompt_tuning.md).

## Cadernos de Exerc√≠cios

| T√≠tulo | Descri√ß√£o | Exerc√≠cio | Link | Colab |
|-------|-------------|----------|------|-------|
| Ajuste fino do LoRA | Aprenda a fazer o ajuste fino de modelos usando adaptadores do LoRA | üê¢ Treine um modelo usando o LoRA< br>üêï Experimente com diferentes valores de classifica√ß√£o<br>ü¶Å Compare o desempenho com o ajuste fino completo | [Exerc√≠cio](./notebooks/finetune_sft_peft.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/finetune_sft_peft.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | |
| Carregue adaptadores LoRA | Aprenda como carregar e usar adaptadores LoRA treinados | üê¢ Carregar adaptadores pr√©-treinados< br>üêï Mesclar adaptadores com o modelo de base<br>ü¶Å Alternar entre v√°rios adaptadores | [Exerc√≠cio](./notebooks/load_lora_adapter.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/load_lora_adapter.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | 
<!-- | Ajuste de prompts | Aprenda como implementar o ajuste de prompts | üê¢ Treine prompts flex√≠veis<br>üêï Compare diferentes estrat√©gias de inicializa√ß√£o< br>ü¶Å Avalie em v√°rias tarefas | [Exerc√≠cio](./notebooks/prompt_tuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/prompt_tuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | -->

## Refer√™ncias

- [Documenta√ß√£o PEFT](https://huggingface.co/docs/peft)
- [Artigo sobre LoRA](https://arxiv.org/abs/2106.09685)
- [Artigo sobre QLoRA](https://arxiv.org/abs/2305.14314)
- [Artigo sobre Ajuste de Prompts](https://arxiv.org/abs/2104.08691)
- [Guia PEFT do Hugging Face](https://huggingface.co/blog/peft)
- [Como ajustar os LLMs em 2024 com o Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl) 
- [TRL](https://huggingface.co/docs/trl/index)